\# Lab 06 ‚Äî –ë–∞–∑–æ–≤–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∏ –¥–æ—Ä–∞–±–æ—Ç–∫–∞

\# Lab 06 ‚Äî Neural Network Baseline and Tuning



---



\## üá∑üá∫ –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è



\### –¶–µ–ª—å —Ä–∞–±–æ—Ç—ã

–°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏, —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ, –∞ –∑–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Å—Ç–∏ –¥–æ—Ä–∞–±–æ—Ç–∫—É –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞.



\### –ó–∞–¥–∞—á–∏

1\. –ü—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (EDA).

2\. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤).

3\. –ü–æ—Å—Ç—Ä–æ–∏—Ç—å baseline-–º–æ–¥–µ–ª—å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏:

&nbsp;  - –≤—ã–±—Ä–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—ë–≤ –∏ –Ω–µ–π—Ä–æ–Ω–æ–≤,

&nbsp;  - –≤—ã–±—Ä–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –¥–ª—è —Å–∫—Ä—ã—Ç—ã—Ö –∏ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—ë–≤,

&nbsp;  - —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –≤—ã–±—Ä–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É –æ—Ü–µ–Ω–∫–∏.

4\. –ü—Ä–æ–≤–µ—Å—Ç–∏ –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (grid search) –¥–ª—è:

&nbsp;  - —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏,

&nbsp;  - Dropout (–Ω–∞–ª–∏—á–∏–µ –∏ –∑–Ω–∞—á–µ–Ω–∏–µ),

&nbsp;  - Batch Normalization (–Ω–∞–ª–∏—á–∏–µ),

&nbsp;  - —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞.

&nbsp;  –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–ª–æ—ë–≤ –æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –∫–∞–∫ –≤ baseline.

5\. –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫–∏ RMSE –æ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

6\. –°—Ä–∞–≤–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–∑–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –∏ –≤—ã–±—Ä–∞—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å.

7\. –°–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã –ø–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ–¥—Ö–æ–¥–æ–≤.



\### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É

\- EDA —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏.

\- –ì—Ä–∞—Ñ–∏–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ RMSE –æ—Ç –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

\- –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏.

\- –í—ã–≤–æ–¥—ã –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —Ä–∞–±–æ—Ç—ã.



---



\## üá¨üáß Task description



\### Goal

Build a baseline neural network for regression, implement training, and tune hyperparameters to improve model performance.



\### Tasks

1\. Perform exploratory data analysis (EDA).

2\. Preprocess data (scaling, normalization, encode categorical features).

3\. Build a baseline neural network:

&nbsp;  - select number of hidden layers and neurons,

&nbsp;  - choose activation functions for hidden and output layers,

&nbsp;  - implement model training and select an evaluation metric.

4\. Perform hyperparameter tuning (grid search) for:

&nbsp;  - activation function,

&nbsp;  - Dropout (presence and value),

&nbsp;  - Batch Normalization (presence),

&nbsp;  - batch size.

&nbsp;  Keep layer architecture same as baseline.

5\. Visualize RMSE dependence on hyperparameter combinations.

6\. Compare different combinations and select the best model.

7\. Draw conclusions on the effectiveness of different approaches.



\### Expected results

\- EDA with explanations.

\- RMSE vs. hyperparameters plots.

\- Justification of the best model selection.

\- Clear conclusions based on results.



