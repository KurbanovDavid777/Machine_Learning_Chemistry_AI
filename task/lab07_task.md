# Lab 07 ‚Äî –ü—Ä–æ—Å—Ç–µ–π—à–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å –Ω—É–ª—è
# Lab 07 ‚Äî Simple Neural Network from Scratch

---

## üá∑üá∫ –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è

### –¶–µ–ª—å —Ä–∞–±–æ—Ç—ã
–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–µ–π—à—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ —Å –Ω—É–ª—è, –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–æ—Ç–æ–≤—ã—Ö —Å–ª–æ—ë–≤, —Ñ—É–Ω–∫—Ü–∏–π –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤, –∞ –∑–∞—Ç–µ–º –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.

### –ó–∞–¥–∞—á–∏
1. –í–∑—è—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –ª—é–±–æ–π –ø—Ä–µ–¥—ã–¥—É—â–µ–π –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π.
2. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å —Å –Ω—É–ª—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PyTorch, NumPy –∏–ª–∏ –¥—Ä—É–≥–æ–≥–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ –¥–ª—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π.
3. –û–±–æ—Å–Ω–æ–≤–∞—Ç—å –≤—ã–±–æ—Ä —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å.
4. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä/–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π.
5. –ü—Ä–æ–≤–µ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏.
6. –°—Ä–∞–≤–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–∑–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π.
7. –°–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã –æ —Ä–∞–±–æ—Ç–µ —Å–µ—Ç–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
- –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ç–∏ —Å –Ω—É–ª—è –±–µ–∑ –≥–æ—Ç–æ–≤—ã—Ö —Å–ª–æ—ë–≤ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤.
- –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –∫–æ–¥—É –∏ –≤—ã–±–æ—Ä—É —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏/–ø–æ—Ç–µ—Ä—å.
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞–∑–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.
- –í—ã–≤–æ–¥—ã –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —Ä–∞–±–æ—Ç—ã.

---

## üá¨üáß Task description

### Goal
Implement a simple neural network for classification or regression from scratch, without using built-in layers, loss functions, or optimizers, and test different architectures.

### Tasks
1. Use data from any previous lab.
2. Implement a neural network from scratch using PyTorch, NumPy, or another math framework.
3. Justify the choice of activation function and loss function.
4. Try several different architectures/configurations.
5. Train the model.
6. Compare the results of different configurations.
7. Draw conclusions about network performance and architecture effectiveness.

### Expected results
- Network implemented from scratch without built-in layers or optimizers.
- Code comments explaining choices of activation/loss functions.
- Comparison of results from different architectures.
- Clear conclusions based on the experiments.
